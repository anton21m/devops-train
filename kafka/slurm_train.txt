https://disk.yandex.ru/i/fUbeOlkysjNYXA Что такое Apache kafka в презентации
https://disk.yandex.ru/i/UuDlsvISoHX_VQ базовые основы
https://disk.yandex.ru/i/MJIIg0omJ4qtxA первая практика

Apache Kafka – это распределенное, отказоустойчивое, горизонтально масштабируемое хранилище, основной структурой данных в котором является append-only лог и которое:

# поддерживает потоковую обработку данных;
# имеет развитую экосистему коннекторов для интеграции с базами данных и другими хранилищами.

Почему выбирают Apache Kafka?

# отлично подходит для хранения и обработки в реальном времени огромных объемов данных;
# обладает возможностью горизонтально масштабировать продюсеров, консьюмеров и брокеров;
# развитая экосистема Kafka Connect позволяет связывать практически любые источники данных с Kafka в считанные минуты, а Kafka Streams дает возможность проводить обработку этих данных в реальном времени.

Как используют Apache Kafka?

Kafka используется, когда речь заходит об обработке больших объемов данных в реальном времени, а также производительности и сохранности данных. Примеры использования технологии:

# брокер сообщений для межсервисного взаимодействия;
# обработка кликстрим действий пользователей;
# система очередей (имейте в виду, что Кафка поддерживает только семантику топиков);
# журналирование;
# сбор метрик;
# commit log;
# центральное хранилище информации.

В чем отличие Kafka в сравнении с сервисами очередей?

Как и сервисы очередей, Kafka условно состоит из трех базовых компонентов: 
# сервера (брокера), продюсера и консьюмера. Главное отличие Kafka от сервисов очередей (например RabbitMQ или Amazon SQS) заключается в том, как сообщения хранятся на брокере, а также потребляются консьюмерами:

# сообщения в Kafka не удаляются по мере их обработки консьюмерами;
# одни и те же сообщения могут быть обработаны сколько угодно раз, в том числе несколькими сервисами одновременно.
Внутренняя структура данных Kafka состоит из:

# Event (сообщение), который включает в себя: ключ (key), значение (value), timestamp и опциональный набор метаданных (headers);
# Topics (топики), в которых организованы и хранятся сообщения. В свою очередь каждый Topic состоит из одной или более партиций;
# Partitions (партиции) - это распределенный отказоустойчивый лог (Log). Сообщения с одинаковыми ключами записываются в одну и ту же партицию.
# У каждой партиции есть один брокер лидер - Leader (принимает сообщения от Producer и в общем случае отдает сообщения консьюмеру), 
# Фолловеры (Follower) являются брокерами, которые хранят реплику всех данных партиции и осуществляют запросы лидеру.

Consumer Groups:

# партиции внутри одной группы назначаются консьюмерам уникально;
# партиции — это основной инструмент масштабирования;
# если консьюмеры не справляются с объемом данных, то необходимо добавить новые партиции в топик и добавить консюмеров в группу;
# важно помнить о гарантии очередности данных, а также то, что партиции невозможно удалить после их создания - придется удалять весь топик целиком.

Что такое Apache Zookeeper?

Zookeeper - один из важных компонентов кластера Kafka, который выполняет роль консистентного хранилища метаданных. В настоящее время Zookeeper является критической зависимостью для Kafka, поскольку именно он способен сказать, живы ли брокеры, какой из брокеров является контроллером, а также в каком состоянии находятся лидеры партиций и их реплики. Важно помнить, что падение Zookeeper равнозначно падению всего кластера Kafka! Поэтому эта система также нуждается в поддержке и обновлении. Но, к счастью, нагрузка на Zookeeper при нормальной работе кластера является минимальной.

# Установка kafka cluster
Для установки kafka просто распакуйте архив https://kafka.apache.org/downloads
wget https://downloads.apache.org/kafka/3.5.1/kafka_2.12-3.5.1.tgz
tar -xvf kafka_2.12-3.5.1.tgz
все скрипты будут в bin

Первым делом мы запускаем Zookeeper. Как мы уже обсуждали, Кафка пользуется зукипером для хранения метаданных, а также для координации своей работы (выбора лидеров партиций и контроллера).

./zookeeper-server-start.sh ../config/zookeeper.properties запустить zookeeper

Запускаем брокер Кафки

./kafka-server-start.sh ../config/server.properties запустить kafka server
Все готово

# Запись и чтение сообщений

Создаем топик с регистрациями
./bin/kafka-topics.sh --create --topic  registrations --bootstrap-server localhost:9092 создать топик kafka c 1 партицией

Посмотрим на его конфигурацию
./bin/kafka-topics.sh --describe --topic registrations --bootstrap-server localhost:9092 показать топик

Для записи сообщения producer:

Давайте запишем первое сообщение
./bin/kafka-console-producer.sh --topic registrations --bootstrap-server localhost:9092
> hello world (enter)
> hello anton (enter)

Для чтения сообщения consumer:

Попробуем его прочитать
./bin/kafka-console-consumer.sh  --topic registrations --bootstrap-server localhost:9092 это не прочитает сообщения т.к. kafka по умолчанию читает сообщения в realtime

И… ничего не происходит!

В эту ситуацию попадают многие люди, впервые использующие кафку. Все дело в том, что консьюмер Kafka по умолчанию начинает читать данные с конца топика (см. настройку auto.offset.reset). Для того чтобы прочитать данные с начала, мы должны переопределить эту конфигу.


./bin/kafka-console-consumer.sh  --topic registrations --bootstrap-server localhost:9092 --consumer-property auto.offset.reset=earliest (--from-beginning) добавим ключ чтобы получить все до запуска терминала

Теперь вы все видим!!!!!!!!!!!!!

Обратим внимание на лог и увидим, что каждый запуск консольного консюмера создает новую группу.

Давайте вместо этого зададим свою:

./bin/kafka-console-consumer.sh  --topic registrations --bootstrap-server localhost:9092 --consumer-property auto.offset.reset=earliest --group anton читать сообщения от группы anton. Если выйти и заново зайти мы уже не увидим сообщения т.к. offset изменился

./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group anton --describe посмотреть offset группы anton

А теперь сбросим позицию обратно на начало
./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group anton --reset-offsets --to-earliest --topic=registrations --execute сбросить offset в группе anton

При новом запуске консюмера снова давайте отключим автоматический коммит оффсетов
./bin/kafka-console-consumer.sh --topic registrations --bootstrap-server localhost:9092 --group slurm --consumer-property auto.offset.reset=earliest --consumer-property enable.auto.commit=false

# Topic Retention Часть 1
Очистка топика
Можно сделать retention (удалие данных из kafka) по времени и размеру партиций

По умолчанию Кафка проверяет, нужно ли удалить данные по ретеншену каждые 5 минут. Давайте сделаем этот интервал меньше — каждую секунду.

изменим настройки брокера для облегчения изучения
остановим брокера CTRL +c
```
cp test-server.prop
vi test-server.prop

log.retention.check.interval.ms=1000 # измените эту настройку на 1000 (1 секунда) (частота проверки retention)

Заупустим kafka сервер с новым конфигурационным файлом
/bin/kafka-server-start.sh ./config/test-server.prop 

./kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name registrations --alter --add-config retention.ms=60000 настройка позволяет удалять сообщения каждые 60 секунд



./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic registrations --from-beginning

Запустив заново консюмера мы увидим, что сообщения действительно удалились. В логе видим “Found deletable segments with base offsets”.

В одном терминале запустим вот такую конструкцию:

touch /tmp/data && tail -f -n0 /tmp/data | ./kafka-console-producer.sh --topic registrations --bootstrap-server localhost:9092 --sync

А во втором терминале - вот такую:
for i in $(seq 1 3600); do echo "test${i}" >> /tmp/data; sleep 1; done

Читая сообщения спустя минуту, мы по-прежнему видим старые сообщения!

Для того чтобы понять, что происходит, мы должны разобраться во внутренней структуре данных партиции. 

Notes: Clean удаляет лишь закрытые сегменты

https://kafka.apache.org/documentation/#configuration информация по конфигурации kafka

Все логи хранятся по умолчанию в /tmp/kafka-logs

Часть 2

изменим roll up на 10 секунд

./kafka-configs.sh -bootstrap-server localhost:9092 --entity-type topics --entity-name registrations --alter --add-config segment.ms=10000

и запустим старые скрипты for

Заглянув в папку с данными, видим активный сегмент (а также старые сегменты, помеченные как “deleted”).

отследим в папке cd /tmp/kafka-configs появление rool up (.deleted)
`watch -n 1 ls -la`

# Log Compaction

Log compaction работает только с закрытыми Partitions

Удаляет данные с одинаковыми ключами, оставляя лишь последний

# ZooKeeper

./zookeeper-shell.sh localhost:2181 подключиться к zookeeper

там будет дерево хранения данных
ls / - показать файлы и папки
get /controller получить состояние контроллера
get /brokers/topics/registrations/partitions/0/state получить состояние партиции
stat /brokers/ids/0 посмотреть метаданные о ноде (эфемерная)
ls /brokers посмотреть список брокеров









 